# ==============================================================================
# 服务配置选项
# ==============================================================================
[SERVICE]
host=
port=10473
prefix=/v1
api_keys=xxx

# ==============================================================================
# 模型配置选项
# ==============================================================================
[MODEL]
model_name=internlm-chat-7b-v1-1
model_path=
adapter_path=
resize_embedding=false
device=cuda
device_map=
gpus=0
num_gpus=1
quantize=
load_in_8bit=
load_in_4bit=
using_ptuning_v2=
context_len=2048
stream_interval=2

# ==============================================================================
# 推理引擎相关
# ==============================================================================
[SERVING]
serving_engine=vllm
use_streamer_v2=false
trust_remote_code=true
tokenize_mode=
tensor_parallel_size=1
dtype=half
gpu_memory_utilization=0.4
max_num_batched_tokens=
max_num_seqs=
quantization_method=
