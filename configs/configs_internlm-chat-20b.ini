# ==============================================================================
# 服务配置选项
# ==============================================================================
[SERVICE]
host=0.0.0.0
port=10470
prefix=/v1
api_keys=xxx

# ==============================================================================
# 模型配置选项
# ==============================================================================
[MODEL]
model_name=internlm-chat-20b
model_path=/IAOdata/models/internlm-chat-20b-20230906/
adapter_path=
resize_embedding=false
device=cuda
device_map=
gpus=1
num_gpus=1
quantize=
load_in_8bit=
load_in_4bit=
using_ptuning_v2=
context_len=2048
stream_interval=2

# ==============================================================================
# 推理引擎相关
# ==============================================================================
[SERVING]
serving_engine=transformers
use_streamer_v2=false
trust_remote_code=true
tokenize_mode=
tensor_parallel_size=
dtype=half
gpu_memory_utilization=
max_num_batched_tokens=
max_num_seqs=
quantization_method=
