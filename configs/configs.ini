# ==============================================================================
# 服务配置选项
# ==============================================================================
[SERVICE]
host=
port=10371
prefix=/v1
api_keys=xxx

# ==============================================================================
# 模型配置选项
# ==============================================================================
[MODEL]
model_name=internlm-7b-v1-1
model_path=/IAOdata/models/internlm-chat-7b-v1-1-20230901/
adapter_path=
resize_embedding=false
device=cuda
device_map=
gpus=1
num_gpus=1
quantize=
load_in_8bit=
load_in_4bit=
using_ptuning_v2=
context_len=4096
stream_interval=2

# ==============================================================================
# 推理引擎相关
# ==============================================================================
[SERVING]
serving_engine=transformers
use_streamer_v2=false
trust_remote_code=true
tokenize_mode=
tensor_parallel_size=
dtype=half
gpu_memory_utilization=
max_num_batched_tokens=
max_num_seqs=
quantization_method=
